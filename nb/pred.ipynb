{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c96d390-24a9-4a5a-99e3-0effa58b0f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1aa524b7-2cbb-4818-a9ac-1346000d4068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5709\n",
      "676\n",
      "844\n"
     ]
    }
   ],
   "source": [
    "tile_dir = '../data/npz_all/npz/tile/xla/'\n",
    "train_dir = tile_dir + 'train/'\n",
    "valid_dir = tile_dir + 'valid/'\n",
    "test_dir = tile_dir + 'test/'\n",
    "\n",
    "print(len(os.listdir(train_dir)))\n",
    "print(len(os.listdir(valid_dir)))\n",
    "print(len(os.listdir(test_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53ca7694-35d0-4570-b1d3-9e5f171bd2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(valid_dir + os.listdir(valid_dir)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c1b8917-26d0-43b5-a080-d034edfcafe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_feat (27, 140)\n",
      "node_opcode (27,)\n",
      "edge_index (26, 2)\n",
      "config_feat (1893, 24)\n",
      "config_runtime (1893,)\n",
      "config_runtime_normalizers (1893,)\n"
     ]
    }
   ],
   "source": [
    "for k, v in data.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "167dcd3a-38d1-472a-86eb-d60acbbcba75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1760332.9302694136"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(data['config_runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a385461-5bfb-4828-ab07-50a11fb0556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slowdown(y_true, y_pred, k):\n",
    "    y_fastest = np.min(y_true)\n",
    "\n",
    "    slowdowns_actual = y_true / y_fastest\n",
    "\n",
    "    top_k_indices = y_pred[:k]\n",
    "    \n",
    "    top_k_predicted_times = np.min(y_true[top_k_indices])\n",
    "\n",
    "    ratio = top_k_predicted_times / y_fastest\n",
    "\n",
    "    return ratio - 1 \n",
    "\n",
    "\n",
    "def speed_score(y_true, y_pred, k):\n",
    "    return 1 - slowdown(y_true, y_pred, k) \n",
    "\n",
    "# print(speed_score(np.array([1.24, 0.231, 4.2, 2.01]), np.array([2, 0, 3, 1]), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8646ae87-9f23-4848-8929-b578f8c719be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayoutDataset(Dataset):\n",
    "    def __init__(self, filenames):\n",
    "        self.filenames = filenames\n",
    "        self.current_file_data = None\n",
    "        self.current_file_idx = -1\n",
    "        self.trials_per_file = self.precompute_trials_per_file()\n",
    "        self.cumulative_trials = np.cumsum(self.trials_per_file)\n",
    "    \n",
    "    def precompute_trials_per_file(self):\n",
    "        trials_per_file = []\n",
    "        for filename in self.filenames:\n",
    "            with np.load(filename, allow_pickle=True) as data:\n",
    "                trials_per_file.append(len(data['config_runtime']))\n",
    "        return trials_per_file\n",
    "    \n",
    "    def load_file(self, filename):\n",
    "        if self.current_file_data is not None:\n",
    "            del self.current_file_data  # Close current file data if any\n",
    "        self.current_file_data = np.load(filename, allow_pickle=True)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.cumulative_trials[-1]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= self.__len__():\n",
    "            raise IndexError(\"Index out of range\")\n",
    "        \n",
    "        file_idx = np.searchsorted(self.cumulative_trials, idx, side='right')\n",
    "        if file_idx != self.current_file_idx:\n",
    "            self.load_file(self.filenames[file_idx])\n",
    "            self.current_file_idx = file_idx\n",
    "\n",
    "        trial_idx = idx - self.cumulative_trials[file_idx - 1] if file_idx > 0 else idx\n",
    "        return self.get_trial_data(self.current_file_data, file_idx, trial_idx)\n",
    "    \n",
    "    def get_trial_data(self, file_data, file_idx, trial_idx):\n",
    "        config_feat = torch.from_numpy(file_data['config_feat'][trial_idx])\n",
    "        node_feat = torch.from_numpy(file_data['node_feat'])\n",
    "        node_opcode = torch.from_numpy(file_data['node_opcode'])\n",
    "        config_runtime = torch.tensor([file_data['config_runtime'][trial_idx] / file_data['config_runtime_normalizers'][trial_idx]])\n",
    "\n",
    "        node_feat = torch.concat([node_feat, node_opcode.unsqueeze(1)], axis=1)\n",
    "        \n",
    "        return config_feat, node_feat, config_runtime, torch.tensor([file_idx]), torch.tensor([trial_idx])\n",
    "\n",
    "\n",
    "\n",
    "def pad_sequence(sequences, batch_first=True, padding_value=-1):\n",
    "    max_len = max([s.size(0) for s in sequences])\n",
    "    batch_size = len(sequences)\n",
    "    max_size = sequences[0].size(1)\n",
    "    padded_batch = torch.full((batch_size, max_len, max_size), padding_value)\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        length = sequence.size(0)\n",
    "        padded_batch[i, :length] = sequence\n",
    "    return padded_batch\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    config_feat_list, node_feat_list, config_runtime_list, file_idx, trial_idx = zip(*batch)\n",
    "\n",
    "    config_feat = torch.stack(config_feat_list)\n",
    "    config_runtime = torch.stack(config_runtime_list)\n",
    "    file_idxs = torch.stack(file_idx)\n",
    "    trial_idxs = torch.stack(trial_idx)\n",
    "    \n",
    "    \n",
    "\n",
    "    node_feat_padded = pad_sequence(node_feat_list, batch_first=True)\n",
    "\n",
    "    return config_feat, node_feat_padded, config_runtime, file_idxs, trial_idxs\n",
    "\n",
    "class BufferedRandomSampler:\n",
    "    def __init__(self, data_source_length, buffer_size=200):\n",
    "        self.data_source_length = data_source_length\n",
    "        self.buffer_size = buffer_size\n",
    "        self.buffer = []\n",
    "        self.index_iter = iter(range(data_source_length))  \n",
    "    \n",
    "    def fill_buffer(self):\n",
    "        try:\n",
    "            while len(self.buffer) < self.buffer_size:\n",
    "                self.buffer.append(next(self.index_iter))\n",
    "        except StopIteration:\n",
    "            pass\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if not self.buffer:  \n",
    "            self.fill_buffer()\n",
    "            if not self.buffer:  \n",
    "                raise StopIteration\n",
    "\n",
    "        random.shuffle(self.buffer)\n",
    "        return self.buffer.pop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df3cff96-73f0-446c-abc8-010c05926f3e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filenames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mfilenames\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'filenames' is not defined"
     ]
    }
   ],
   "source": [
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c28d675-f01c-4518-81bc-e44440b8db22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished dataset 1042735\n",
      "[   1893    1961    3451    3618    4278    4472    4662    4847    4956\n",
      "    5845    5849   14535   14724   14809   18055   19647   20457   20496\n",
      "   27197   28033   28092   28101   28940   28957   29121   29514   29541\n",
      "   29729   29750   30434   31520   31640   33342   34260   34419   34450\n",
      "   36075   36195   36232   36838   36884   37160   37245   45240   45284\n",
      "   47141   47549   53602   53636   54963   55049   55212   57045   57931\n",
      "   58401   61268   61277   61293   65444   66003   68670   68836   69277\n",
      "   69408   71409   71863   77246   77271   79270   79301   79544   79554\n",
      "   80705   80723   82165   82169   82463   86463   88276   91227   93120\n",
      "   96294   96307   98292  104292  104434  110182  120165  122771  123228\n",
      "  123286  123451  123617  124381  124393  124403  124458  125973  126154\n",
      "  127382  133302  133569  136303  140946  140979  141190  147682  147767\n",
      "  148599  157591  157836  158005  158075  158729  159753  160975  161581\n",
      "  161787  171777  171782  173414  174021  174034  175138  179744  180366\n",
      "  185228  189359  189544  191479  191664  192522  192892  193694  197188\n",
      "  201021  202565  203507  203538  204793  208425  210392  210401  211412\n",
      "  211443  214349  215480  217644  220527  220536  220645  222644  222780\n",
      "  230773  232473  233313  233471  239081  239139  249130  253130  253361\n",
      "  253723  253765  253776  254051  254068  254107  254178  255315  255563\n",
      "  255719  259302  259757  261846  261852  267499  267548  267559  268406\n",
      "  268451  268460  268591  268623  268644  268661  273721  275326  283277\n",
      "  284382  284833  285067  286083  286114  287078  287207  288247  289192\n",
      "  290120  290361  291361  291550  293746  301738  301823  302013  303638\n",
      "  309967  310961  311992  315327  315491  316531  316654  318623  318653\n",
      "  318842  318972  319260  319293  322761  325006  328839  329961  330068\n",
      "  330951  337946  338158  338883  340545  340571  342309  342826  343604\n",
      "  352484  353236  353273  353957  355956  357149  357160  358214  360459\n",
      "  360636  369259  370583  370742  371801  371836  373235  375893  375927\n",
      "  375932  383823  384030  384069  384543  384553  389404  392372  392405\n",
      "  393900  394310  394794  394799  394854  394863  394890  394922  397254\n",
      "  398619  398752  398881  404287  407886  408858  409942  410185  410633\n",
      "  410663  410826  411709  412051  417442  417496  420458  420472  420493\n",
      "  430490  439304  440270  440634  441233  441919  448930  449069  450093\n",
      "  451152  453150  454107  460814  460869  460893  461738  463326  464206\n",
      "  464224  467519  471513  471526  471532  472215  472312  472380  475875\n",
      "  477990  477999  483988  486888  496882  497008  497019  497438  499119\n",
      "  499921  500723  503441  504891  505958  507092  507188  507235  510783\n",
      "  511097  513893  520834  522323  529657  530258  533707  539735  542096\n",
      "  548665  556658  557712  558209  559049  559134  562355  565657  565869\n",
      "  565885  566437  566500  569730  570511  570557  572840  573178  573355\n",
      "  573365  573727  574743  575342  575477  578547  578751  579507  581029\n",
      "  583361  583378  584002  585139  585477  585945  593879  594105  595786\n",
      "  596029  596214  596419  597916  600638  602087  602536  605207  608770\n",
      "  609626  609636  610117  610128  610516  610554  610721  612421  612452\n",
      "  613539  614895  615775  616281  616569  619540  620069  620872  621919\n",
      "  622498  623070  623228  628489  631451  631491  632260  634639  635511\n",
      "  635524  635651  635690  642072  643290  643299  643505  644711  645711\n",
      "  646371  646395  646406  647339  648471  651717  653425  653555  653801\n",
      "  653899  655244  657978  658244  658304  667304  668441  674118  676314\n",
      "  676323  676869  686860  690475  696860  697024  697827  698481  704635\n",
      "  705137  705224  705675  705961  706459  706469  706632  706662  706668\n",
      "  709164  710217  710406  710601  710716  717710  717894  719154  719845\n",
      "  723008  731960  734206  736969  738175  739387  740332  740452  742187\n",
      "  742229  742240  742250  743284  743512  743615  744169  745119  748587\n",
      "  751796  753046  754194  757648  757882  758393  758601  761717  761743\n",
      "  761933  771209  775066  775260  777259  777467  777647  778739  788678\n",
      "  788684  788826  789240  789246  789431  789699  789725  789896  799830\n",
      "  800033  802628  806032  809253  809337  819278  819689  819921  820130\n",
      "  821066  821526  821558  828966  829218  829626  829913  829919  833712\n",
      "  834419  834803  835683  837676  838049  838085  838725  841209  841218\n",
      "  841271  843605  844145  844347  844365  844961  845602  846531  856522\n",
      "  856568  857874  859067  859811  860000  863796  871782  871988  877688\n",
      "  881242  881377  881649  881680  882056  883124  883964  884023  885168\n",
      "  889790  892644  895946  897302  897320  897958  899025  899190  899433\n",
      "  906197  909080  909759  909770  910272  912443  915617  915643  919680\n",
      "  919787  919831  921529  922461  923694  933290  934179  934470  934950\n",
      "  934974  935602  936042  936076  936327  936469  937588  937670  938624\n",
      "  938649  941389  941495  941541  941911  941986  942022  942084  943417\n",
      "  943660  943788  948779  948933  949003  950494  953081  953178  953367\n",
      "  953863  955392  955895  958867  959714  967708  968526  968552  969007\n",
      "  972639  973107  976661  977344  981140  981392  991383  992587  992655\n",
      "  992889  992982  993169  993178  993204  993466  993479  993663  993673\n",
      "  994523  997263 1007249 1007664 1007718 1007724 1015717 1015841 1015859\n",
      " 1020826 1021052 1022099 1022261 1030951 1031796 1031866 1033464 1033698\n",
      " 1033818 1036632 1037094 1037134 1037413 1037578 1037773 1038529 1041465\n",
      " 1042735]\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m random_model\n\u001b[1;32m     13\u001b[0m preds \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataset):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# config_feat, node_feat, config_runtime, file_idx, trial_idx = data\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# runtime = model(node_feat, config_feat)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# preds[file_idx].append({'runtime': runtime, 'pred': config_runtime.item()})\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28mprint\u001b[39m(i)\n",
      "Cell \u001b[0;32mIn[9], line 34\u001b[0m, in \u001b[0;36mLayoutDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_file_idx \u001b[38;5;241m=\u001b[39m file_idx\n\u001b[1;32m     33\u001b[0m trial_idx \u001b[38;5;241m=\u001b[39m idx \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcumulative_trials[file_idx \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file_idx \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m idx\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_trial_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_file_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial_idx\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 39\u001b[0m, in \u001b[0;36mLayoutDataset.get_trial_data\u001b[0;34m(self, file_data, file_idx, trial_idx)\u001b[0m\n\u001b[1;32m     37\u001b[0m config_feat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(file_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig_feat\u001b[39m\u001b[38;5;124m'\u001b[39m][trial_idx])\n\u001b[1;32m     38\u001b[0m node_feat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(file_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnode_feat\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 39\u001b[0m node_opcode \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[43mfile_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnode_opcode\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     40\u001b[0m config_runtime \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([file_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig_runtime\u001b[39m\u001b[38;5;124m'\u001b[39m][trial_idx] \u001b[38;5;241m/\u001b[39m file_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig_runtime_normalizers\u001b[39m\u001b[38;5;124m'\u001b[39m][trial_idx]])\n\u001b[1;32m     42\u001b[0m node_feat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcat([node_feat, node_opcode\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/code/tpu_graphs/venv/lib/python3.10/site-packages/numpy/lib/npyio.py:253\u001b[0m, in \u001b[0;36mNpzFile.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m magic \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mMAGIC_PREFIX:\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28mbytes\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mopen(key)\n\u001b[0;32m--> 253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mread(key)\n",
      "File \u001b[0;32m~/code/tpu_graphs/venv/lib/python3.10/site-packages/numpy/lib/format.py:777\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    775\u001b[0m version \u001b[38;5;241m=\u001b[39m read_magic(fp)\n\u001b[1;32m    776\u001b[0m _check_version(version)\n\u001b[0;32m--> 777\u001b[0m shape, fortran_order, dtype \u001b[38;5;241m=\u001b[39m \u001b[43m_read_array_header\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    780\u001b[0m     count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def random_model(node_feat, config_feat):\n",
    "    return random.random()\n",
    "\n",
    "filenames = [valid_dir + f for f in os.listdir(valid_dir)]\n",
    "\n",
    "dataset = LayoutDataset(filenames=filenames) \n",
    "print('finished dataset', len(dataset))\n",
    "# print(dataset.cumulative_trials)\n",
    "sampler = BufferedRandomSampler(len(dataset))\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False, collate_fn=custom_collate_fn)\n",
    "model = random_model\n",
    "\n",
    "preds = defaultdict(list)\n",
    "for i, data in enumerate(dataset):\n",
    "    # config_feat, node_feat, config_runtime, file_idx, trial_idx = data\n",
    "\n",
    "    # runtime = model(node_feat, config_feat)\n",
    "\n",
    "    # preds[file_idx].append({'runtime': runtime, 'pred': config_runtime.item()})\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "\n",
    "scores = []\n",
    "for file in preds.values():\n",
    "    file = sorted(file, key=lambda x: x['runtime'])\n",
    "    for i, d in enumerate(file):\n",
    "        d['idx'] = i\n",
    "    file = sorted(file, key=lambda x: x['pred'])\n",
    "    indices = np.array([f['idx'] for f in file])\n",
    "    runtimes = np.array([f['runtime'] for f in file])\n",
    "\n",
    "    print(file)\n",
    "\n",
    "    scores.append(speed_score(runtimes, indices, 3))\n",
    "print(np.mean(scores)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57f5408-c4e1-4bed-8a10-b005a96eeda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullHeightConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_width, stride_width=1):\n",
    "        super(FullHeightConv, self).__init__()\n",
    "        # The kernel size is (24, kernel_width)\n",
    "        # Stride is (1, stride_width) to move one step down and stride_width steps to the right\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=(24, kernel_width),\n",
    "            stride=(1, stride_width)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "# Example usage:\n",
    "# Assuming the input has 1 channel, we want to produce 16 feature maps,\n",
    "# and we want a kernel width of 3 with a stride of 1 in the N dimension.\n",
    "conv_layer = FullHeightConv(in_channels=1, out_channels=16, kernel_width=3, stride_width=1)\n",
    "\n",
    "# Now let's create a dummy input tensor of shape (batch_size, channels, 24, N)\n",
    "# where N could be any size, for instance, let's take N=50\n",
    "input_tensor = torch.randn(2, 1, 24, 50)  # batch_size=2, channels=1, height=24, width=50\n",
    "\n",
    "# Apply the convolutional layer to the input\n",
    "output = conv_layer(input_tensor)\n",
    "\n",
    "# Print the output shape\n",
    "print(output.shape)  # This will print the shape of the output tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab6b165a-8aa2-481a-917c-27914b8fe1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "1000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "1000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "1000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "0\n",
      "1000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "1000\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "1000\n",
      "0\n",
      "1000\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "0\n",
      "1000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "0\n",
      "1000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "1000\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "1000\n",
      "0\n",
      "1000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "0\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "for file in filenames:\n",
    "    data= np.load(file)\n",
    "    for i in range(len(data['config_runtime'])):\n",
    "        if i % 1000 == 0:\n",
    "            print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2161a360-27c4-46ff-8c22-163ecf1e0863",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
